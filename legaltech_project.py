# -*- coding: utf-8 -*-
"""LegalTech Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EVpHKkcMjmwzt3BQz66N76sKcEI80U-D

Step 1: Data Preprocessing for Clause Risk Detection
"""

import pandas as pd
import numpy as np
import re
import spacy
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score
from imblearn.over_sampling import RandomOverSampler
from scipy.sparse import hstack

# Load and preprocess data
df = pd.read_csv("Clause Dataset.csv", encoding='latin-1')
df = df[['Clause Text', 'Clause Type', 'Risk Level']]

# Cleaning
nlp = spacy.load("en_core_web_sm")

def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)
    return re.sub(r'\s+', ' ', text).strip()

def tokenize_and_lemmatize(text):
    doc = nlp(text)
    return " ".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])

# Apply cleaning
df['Cleaned Clause'] = df['Clause Text'].astype(str).apply(clean_text)
df['Lemmatized Clause'] = df['Cleaned Clause'].apply(tokenize_and_lemmatize)
df['clause_len'] = df['Lemmatized Clause'].apply(lambda x: len(x.split()))

# Drop risk levels that appear only once
counts = df['Risk Level'].value_counts()
valid_risk_levels = counts[counts > 1].index
df = df[df['Risk Level'].isin(valid_risk_levels)]

# Label encoding
y_risk = LabelEncoder().fit_transform(df['Risk Level'])

# TF-IDF Vectorizer
tfidf = TfidfVectorizer(max_features=5000)
X_tfidf = tfidf.fit_transform(df['Lemmatized Clause'])

# Combine TF-IDF with clause length
X_final = hstack([X_tfidf, np.array(df['clause_len']).reshape(-1, 1)])

# Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(X_final, y_risk, test_size=0.2, stratify=y_risk, random_state=42)

# Oversampling
ros = RandomOverSampler(random_state=42)
X_train_bal, y_train_bal = ros.fit_resample(X_train, y_train)

# Models
logreg = LogisticRegression(max_iter=1000, class_weight='balanced')
rf = RandomForestClassifier(n_estimators=300, class_weight='balanced', random_state=42)
svc = SVC(probability=True, class_weight='balanced')
gb = GradientBoostingClassifier(n_estimators=300, random_state=42)

# Train and Evaluate
models = {
    "Logistic Regression": logreg,
    "Random Forest": rf,
    "SVC": svc,
    "Gradient Boosting": gb
}

for name, model in models.items():
    model.fit(X_train_bal, y_train_bal)
    y_pred = model.predict(X_test)
    print(f"\n==== {name} - Risk Level ====")
    print("Accuracy:", accuracy_score(y_test, y_pred))
    print(classification_report(y_test, y_pred))

import pandas as pd
import numpy as np
import re
import spacy
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
from imblearn.over_sampling import RandomOverSampler
from scipy.sparse import hstack
import shap
import lime
from lime.lime_text import LimeTextExplainer

# Load and preprocess data
df = pd.read_csv("/content/Clause Dataset.csv", encoding='latin-1')
df = df[['Clause Text', 'Clause Type', 'Risk Level']]

# Cleaning
nlp = spacy.load("en_core_web_sm")

def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)
    return re.sub(r'\s+', ' ', text).strip()

def tokenize_and_lemmatize(text):
    doc = nlp(text)
    return " ".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])

# Apply cleaning
df['Cleaned Clause'] = df['Clause Text'].astype(str).apply(clean_text)
df['Lemmatized Clause'] = df['Cleaned Clause'].apply(tokenize_and_lemmatize)
df['clause_len'] = df['Lemmatized Clause'].apply(lambda x: len(x.split()))

# Drop risk levels that appear only once
counts = df['Risk Level'].value_counts()
valid_risk_levels = counts[counts > 1].index
df = df[df['Risk Level'].isin(valid_risk_levels)]

# Label encoding
y_risk = LabelEncoder().fit_transform(df['Risk Level'])
label_names = list(LabelEncoder().fit(df['Risk Level']).classes_)

# TF-IDF Vectorizer
tfidf = TfidfVectorizer(max_features=5000)
X_tfidf = tfidf.fit_transform(df['Lemmatized Clause'])

# Combine TF-IDF with clause length
X_final = hstack([X_tfidf, np.array(df['clause_len']).reshape(-1, 1)])

# Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(X_final, y_risk, test_size=0.2, stratify=y_risk, random_state=42)

# Oversampling
ros = RandomOverSampler(random_state=42)
X_train_bal, y_train_bal = ros.fit_resample(X_train, y_train)

# Logistic Regression with balanced class weights
logreg = LogisticRegression(max_iter=1000, class_weight='balanced')
logreg.fit(X_train_bal, y_train_bal)
y_pred = logreg.predict(X_test)

# Evaluation
print("\n==== Logistic Regression - Risk Level ====")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=label_names))

# === LIME Explanation ===
class TfidfPredictWrapper:
    def __init__(self, model, vectorizer):
        self.model = model
        self.vectorizer = vectorizer

    def predict_proba(self, texts):
        X_text = self.vectorizer.transform(texts)
        X_len = np.array([len(text.split()) for text in texts]).reshape(-1, 1)
        X_combined = hstack([X_text, X_len])
        return self.model.predict_proba(X_combined)

lime_explainer = LimeTextExplainer(class_names=label_names)
wrapper = TfidfPredictWrapper(logreg, tfidf)

sample_clause = df['Clause Text'].iloc[0]  # Example clause to explain
exp = lime_explainer.explain_instance(sample_clause, wrapper.predict_proba, num_features=10)
exp.show_in_notebook()

import pandas as pd
import numpy as np
import re
import spacy
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
from imblearn.over_sampling import RandomOverSampler
from scipy.sparse import hstack
import lime
import lime.lime_text
from sklearn.pipeline import make_pipeline

# Load and preprocess data
df = pd.read_csv("/content/Clause Dataset.csv", encoding='latin-1')
df = df[['Clause Text', 'Risk Level']]

# Cleaning
nlp = spacy.load("en_core_web_sm")

def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)
    return re.sub(r'\s+', ' ', text).strip()

def tokenize_and_lemmatize(text):
    doc = nlp(text)
    return " ".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])

# Apply cleaning
df['Cleaned Clause'] = df['Clause Text'].astype(str).apply(clean_text)
df['Lemmatized Clause'] = df['Cleaned Clause'].apply(tokenize_and_lemmatize)
df['clause_len'] = df['Lemmatized Clause'].apply(lambda x: len(x.split()))

# Drop rare risk levels
df = df[df['Risk Level'].map(df['Risk Level'].value_counts()) > 1]

# Label encoding
label_encoder = LabelEncoder()
y_risk = label_encoder.fit_transform(df['Risk Level'])

# TF-IDF Vectorizer
tfidf = TfidfVectorizer(max_features=5000)
X_tfidf = tfidf.fit_transform(df['Lemmatized Clause'])
X_final = hstack([X_tfidf, np.array(df['clause_len']).reshape(-1, 1)])

# Train/Test Split
X_train, X_test, y_train, y_test, text_train, text_test = train_test_split(
    X_final, y_risk, df['Lemmatized Clause'], test_size=0.2, stratify=y_risk, random_state=42
)

# Oversampling
ros = RandomOverSampler(random_state=42)
X_train_bal, y_train_bal = ros.fit_resample(X_train, y_train)

# Logistic Regression
logreg = LogisticRegression(max_iter=1000, class_weight='balanced')
logreg.fit(X_train_bal, y_train_bal)
y_pred = logreg.predict(X_test)

# Evaluation
print("\n==== Logistic Regression - Risk Level ====")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# LIME for interpretability
# Create a pipeline for LIME (uses original text input)
tfidf_lime = TfidfVectorizer(max_features=5000)
X_text = tfidf_lime.fit_transform(df['Lemmatized Clause'])
model_for_lime = LogisticRegression(max_iter=1000, class_weight='balanced')
model_for_lime.fit(X_text, y_risk)
pipeline = make_pipeline(tfidf_lime, model_for_lime)

# LIME explainer
class_names = label_encoder.classes_
explainer = lime.lime_text.LimeTextExplainer(class_names=class_names)

# Example clause for explanation
example_idx = 0
example_text = df.iloc[example_idx]['Lemmatized Clause']
exp = explainer.explain_instance(example_text, pipeline.predict_proba, num_features=10)
exp.show_in_notebook(text=True)

# To visualize explanation in notebook or export:
# exp.save_to_file('/content/lime_explanation.html')

import streamlit as st
import pandas as pd
import numpy as np
import re
import spacy
import lime
import lime.lime_text
from sklearn.linear_model import LogisticRegression
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import make_pipeline
from sklearn.metrics import classification_report, accuracy_score
from imblearn.over_sampling import RandomOverSampler
from scipy.sparse import hstack

# Load spaCy
nlp = spacy.load("en_core_web_sm")

# Cleaning Functions
def clean_text(text):
    text = text.lower()
    text = re.sub(r'[^a-z\s]', '', text)
    return re.sub(r'\s+', ' ', text).strip()

def tokenize_and_lemmatize(text):
    doc = nlp(text)
    return " ".join([token.lemma_ for token in doc if not token.is_stop and not token.is_punct])

# Load and preprocess dataset
df = pd.read_csv("/content/Clause Dataset.csv", encoding='latin-1')
df = df[['Clause Text', 'Risk Level']]
df.dropna(inplace=True)
df['Cleaned Clause'] = df['Clause Text'].astype(str).apply(clean_text)
df['Lemmatized Clause'] = df['Cleaned Clause'].apply(tokenize_and_lemmatize)
df['clause_len'] = df['Lemmatized Clause'].apply(lambda x: len(x.split()))

# Drop rare risk levels
df = df[df['Risk Level'].map(df['Risk Level'].value_counts()) > 1]

# Encode labels
label_encoder = LabelEncoder()
y_risk = label_encoder.fit_transform(df['Risk Level'])

# TF-IDF
tfidf = TfidfVectorizer(max_features=5000)
X_tfidf = tfidf.fit_transform(df['Lemmatized Clause'])
X_final = hstack([X_tfidf, np.array(df['clause_len']).reshape(-1, 1)])

# Split and balance
X_train, X_test, y_train, y_test, text_train, text_test = train_test_split(
    X_final, y_risk, df['Lemmatized Clause'], test_size=0.2, stratify=y_risk, random_state=42
)
ros = RandomOverSampler(random_state=42)
X_train_bal, y_train_bal = ros.fit_resample(X_train, y_train)

# Train logistic regression
logreg = LogisticRegression(max_iter=1000, class_weight='balanced')
logreg.fit(X_train_bal, y_train_bal)

# LIME setup
lime_vectorizer = TfidfVectorizer(max_features=5000)
lime_pipeline = make_pipeline(lime_vectorizer, LogisticRegression(max_iter=1000, class_weight='balanced'))
lime_pipeline.fit(df['Lemmatized Clause'], y_risk)
explainer = lime.lime_text.LimeTextExplainer(class_names=label_encoder.classes_)

# --- Streamlit UI ---
st.set_page_config(page_title="Clause Risk Analyzer", layout="wide")
st.title("ðŸ“„ Clause Risk Level Analyzer")
st.markdown("""
Upload a text document containing **multiple legal clauses** (one clause per line).
This tool will:
- Predict **Risk Level** for each clause
- Show **LIME explanations** and **simplified summaries** of why that prediction was made
""")

with st.sidebar:
    st.header("â„¹ï¸ About")
    st.markdown("This tool uses a Logistic Regression model trained on TF-IDF vectors from legal clauses, along with LIME to explain predictions.")

uploaded_file = st.file_uploader("ðŸ“‚ Upload a .txt document", type=["txt"])

if uploaded_file:
    content = uploaded_file.read().decode("utf-8")
    clauses = [clause.strip() for clause in content.split("\n") if clause.strip()]

    if st.button("ðŸ” Analyze Clauses"):
        st.subheader("ðŸ”Ž Results")
        for i, clause in enumerate(clauses):
            cleaned = clean_text(clause)
            lemmatized = tokenize_and_lemmatize(cleaned)
            pred = lime_pipeline.predict([lemmatized])[0]
            pred_label = label_encoder.inverse_transform([pred])[0]

            col1, col2 = st.columns([1, 2])
            with col1:
                st.markdown(f"### ðŸ§¾ Clause {i+1}")
            with col2:
                st.markdown(f"**Predicted Risk Level:** `{pred_label}`")

            st.markdown(f"> {clause}")

            with st.expander("ðŸ” LIME Explanation + Summary"):
                explanation = explainer.explain_instance(
                    lemmatized, lime_pipeline.predict_proba, num_features=10
                )
                st.components.v1.html(explanation.as_html(), height=500, scrolling=True)

                top_words = [term for term, weight in explanation.as_list() if weight > 0][:5]
                simplified = (
                    f"The model focused on these keywords for the risk prediction: **{', '.join(top_words)}**"
                    if top_words else "No strong keywords were found."
                )
                st.info(simplified)

        st.success("âœ… Analysis complete! Expand the boxes to explore why each clause received its risk label.")
